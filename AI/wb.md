# 가중치, 편향 cc.선형회귀

### 가중치 

선형회귀에서 가중치는 입력 값에 곱해지는 값으로 입력의 중요도를 조절한다.

y = w * x가 있을때 w가 가중치다.

예시로 공부시간(x) -> y 모델에서 w가 공부시간에 큰 영향을 준다는 것을 알 수 있다.

### 편향

결과에 더해지는 상수항으로 입력이 0이어도 출력이 일정값 이상으로 나오도록 해준다.

y = w * x + b로 공부를 아예 하지 않아도 (x = 0) b = 10이라면 10점이상은 맞는다에 대한 설정이 가능하다.

이게 편향.

즉 입력 비율의 조정은 가중치고, 그래프 위아래로 평행 이동 (절편 역할)을 해주는 것은 편향이다.

<br>

## weight bias

**가중치 w**는 데이터가 얼마나 중요하지 결정하는데 예를들어 고양이 귀 부분의 픽셀이 결과에 중요한지 아닌지를 가중치가 결정한다.

이미지 분류에서 고양이 귀를 통해 분류를 하는 모델이라면 가중치가 높게 산정될 것이다. 학습 과정에서 이는 계속 업데이트 되며 

데이터의 패턴을 학습하게 해준다. 직관적으로는 입력 특징의 중요도라고도 할 수 있겠다.

**편향 b**는 출력 값을 위아래로 이동시키는 조정값으로 신경망에서 활성화 함수 

(ReLU, 시그모이드) 적용전 선형결합 결과를 조금 더 유연하게 이동시켜준다.

어떤 입력이 0이여도 어떤 뉴런이 활성화되도록 하는 역할을 한다. 직관적으로는 문턱값같은 역할

한 뉴런의 출력은 보통 이렇게 표현된다. `y=f(w1​x1​+w2​x2​+⋯+wn​xn​+b)`

f는 활성화 함수 wi는 각 입력 xi의 가중치 b는 편향이다.