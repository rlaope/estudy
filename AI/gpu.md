# GPU 아키텍처

### SIMT, Warp

GPU의 연산구조는 하나의 명령어가 다수의 데이터 요소를 동시에 처리하는 구조다

SIMT는 Single Instruction, Multiple Threads의 약자로 연산 제어 유닛 instruction dispatcher이 하나의 명령어를 내리면 여러개의 cuda 코어 (ALU)가 각자 할당된 데이터를 바탕으로 동일한 명령을 수행한다

워프 Warp(Subgroup)은 하드웨어 스레드를 관리하는 최소 단위로 NVIDIA 기준 32개 스레드가 하나의 워프로 묶이며 이들은 동일한 프로그램 카운터를 공유해 완전히 동시에 실행된다.

Branch Divergence(분기 분산)은 if else 문 등에 의해 워프 내 스레드들이 서로 다른 실행 경로를 가지게되면, 하드웨어는 각 경로를 순차적으로 실행한다. 이때 실행되지 않는 경로의 스레드는 비활성화되어 masked out 연산 자원 효율이 떨어진다.

### 메모리 계층 구조

gpu 성능 최적화의 핵심은 연산 유닛과 물리적으로 가까운 메모리를 활용하여 데이터 접근 레이턴시를 줄이는 것이다.

- **Registers:** Streaming Multiprocessor SM 내부에 있고 접근 범위는 스레드다. 지연시간이 거의 없고 스레드당 할당량이 정해졌이므로 초과시 기판 메모리로 밀려난다 spill
- **Shared Memory:** SM 내부 On-chip에 있고 Block이 접근 범위이며 프로그래머가 코드로 제어하는 SRAM 공간이다 L1 캐시와 동일한 고속 대역폭을 가진다.
- **L1/L2 Cache:** 칩 내부에 있고 SM / Device가 접근범위이며 데이터 재사용성을 높이기 위해 하드웨어가 자동으로 관리한다.
- **Global Memory:** Device VRAM에 위치해있고 Grdid 가 접근범위이며 HBM/GDDR 기반의 오프칩 메모리다 용량은 크나 레이턴시가 수백사이클 400~800cycle에 달한다.

### Optimization

하드웨어 관점에서 gpu 최적화와 핵심 원리에 대해서 알아보겠다.

#### 메모리 병합 memory coalescing

글로벌 메모리 VRAM에서 데이터를 가져올때 워프 내 32개의 스레드가 연속적이고 정렬된 주소에서 접근하면

이를 단일 트랜잭션으로 처리한다.

주소가 파편화 되어있으면 여러번의 메모리 요청이 발생해 대역폭 낭비가 심해진다.

#### 뱅크 충돌

공유 메모리는 병렬 접근을 위해 일반적으로 32개의 독립적인 뱅크로 나뉘어 있는데

만약 워프 내 서로다른 스레드가 동일한 뱅크의 다른 주소에 동시에 접근하려하면 접근이 직렬화되어 성능이 저하된다.

#### 하드웨어를 알아야 하는이유

현대 gpu 연산에서는 대부분 연산 성능 자체보다 메모리 대역폭에 병목이 발생하는 memory bound 특성을 보인다.

따라서 데이터 레이아웃을 하드웨어 트랜잭션 단위와 캐시 라인에 맞춰 설계해야만 gpu의 이론적 최대 성능을 도달할 수 있따.

