# 과대적합, 과소적합

과대적합과 과소적합은 머신러닝 훈련 과정중에 발생할 수 있는 문제중 하나로 데이터량, 특성, 샘플등으로 인해 발생하는 문제와는 조금 다르다.

데이터로 인해 발생할 수 있는 문제점이라기 보단, 훈련 알고리즘으로 인해 발생하는 문제라고 분류할 수 있다.

## 과대적합

훈련 세트에 특화되어 일반화 성능이 떨어지는 현상을 말한다. 이는 훈련세트에 잘 맞기 때문에 결과는 좋게 나타난다고 오해할 수 있지만 전혀 그렇지 않다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FLLGQ3%2Fbtq3mcEvOEY%2FAAAAAAAAAAAAAAAAAAAAAPyZ-NEA6AOqPLOC9akeo5oBJrrSNL2GM4ED9qfDmRFd%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3DuyzgaVb2s0u5sxyN8cuMorU6D5g%253D)

사진상의 점들은 데이터를 나타내고 있지만, 그 사이에 직선 또는 포물선을 통해 예측 데이터를 보여준다.

검은색 선들은 주어진 데이터들을 통해 어느정도 오차는 있겠지만, 새로운 데이터에 대하여 예측할 수 있는 선들로 나타내진다, 하지만 파란색선은 데이터마다 커다란 변동성이 있어 모델의 안정성이 떨어진다.

예시로 어떤게 있을까? 공에 대한 데이터를 학습한 머신러닝 모델이 있다고 가정해보자. 축구공, 농구공, 야구공을 학습하고있다. 

근데 모델이 너무 과대적합하게 학습하는 경우는 동그란 형체가 공이라고 판단하는것 외에 실밥, 무게, 밀도, 가죽등을 학습했다고 쳐보자. 그럼 탁구공같은 데이터가 새로 들어오게된다면? 모델은 탁구공을 공으로 분류하지 못할것이다.

**과대적합을 해결하는 방법**
1. 충분한 양의 데이터를 사용한다 (단순)
2. 규제를 걸어서 과대적합을 감소시킨다.

규제의 예시로는 위 사진의 파란색, 초록색 선과 같이 고차함수로 이루어져 있는 모델들을 1차 또는 2차로 낮추어 검은색 직선처럼 표현하도록 하는것이다. 이는 하이퍼 파라미터를 통해 조절할 수 있다.

하이퍼 파라미터는 담시간에 알아보자.


<br>

## 과소적합

과소적합은 과대랑 반대로 모델이 너무나도 단순해 훈련 세트를 잘 학습하지 못하는 경우다. 

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbL11gd%2Fbtq3mYZWvZ1%2FAAAAAAAAAAAAAAAAAAAAAKPC0KJ3bey_xldh8QQRLHu12Hqubs8qO1inMac7HicD%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3DdgRQqTDBxLkl5OQ%252FWVoFED13BPw%253D)

다음과 같이 데이터들이 분포되어 있을 때, 점들의 분포가 초록색 선이랑 비슷하게 분포되어 있다는것을 에측할 수 있지만 파란색 선은? 표현이 되지 않는다.

이러한 경우 파란색 선은 과소적합된 모델로 정확성이 떨어지며 좋은 모델이라고 평가하기 어렵다.

이를 해결하기 위해서는 파란색 선을 2차원 포물선으로 바꿔주어야한다.

공에 대한 특징을 학습한 모델이 있다고 했을때 데이터가 너무 적어 동그란 형체면 모든것을 다 공으로 구별해버릴 수가 있을것이다. 대표적으로 대머리 김계란 아저씨 머리통을 넣으면 공으로 판단할 수도 있다. 근데 김계란 아저씨 머리는 정확도가 겁나 높아도 공으로 들어갈수도

**과소적합 해결 방법**
1. 보다 더 많은 모델 파라미터를 사용하는 모델을 적용한다.
2. 보다 좋은 특성을 활용한다.
3. 규제 강도를 낮추어 과소 적합을 감소시킨다.

